{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LuluW8071/Text-Sentiment-Analysis/blob/main/Text-Sentiment-Analysis-using-BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMxocdwKAhgv"
      },
      "source": [
        "# Text-Sentiment-Analysis-using-BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VFlkWVYFy-QA",
        "outputId": "bb659b09-ed2c-427a-d40b-7b669f597cfc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing installation: transformers 4.38.2\n",
            "Uninstalling transformers-4.38.2:\n",
            "  Successfully uninstalled transformers-4.38.2\n",
            "Collecting transformers[torch]\n",
            "  Downloading transformers-4.39.3-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.2.1+cu121)\n",
            "Collecting accelerate>=0.21.0 (from transformers[torch])\n",
            "  Downloading accelerate-0.29.2-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.4/297.4 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.21.0->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers[torch]) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (3.1.3)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch->transformers[torch])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch->transformers[torch])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->transformers[torch]) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch->transformers[torch])\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->transformers[torch]) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->transformers[torch]) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, transformers, accelerate\n",
            "Successfully installed accelerate-0.29.2 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 transformers-4.39.3\n"
          ]
        }
      ],
      "source": [
        "# Install new version of transformers, if you running this notebook for 1st time on the gpu, after restarting the runtime\n",
        "# Comment it\n",
        "!pip uninstall transformers -y\n",
        "!pip install transformers[torch]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39k-BncjiZtY"
      },
      "source": [
        "## 1. Download and Load the dataset\n",
        "\n",
        "The dataset that the following script will download is a combination of the Yelp Polarity Dataset and the IMDb Movie Dataset. The Yelp Polarity Dataset has been preprocessed by selecting specific columns to create a dataset suitable for sentiment analysis. This preprocessed dataset has been merged with the IMDb Movie Dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9vIPvXLiWNx",
        "outputId": "5fbba1c8-86fd-4f36-e3ec-bc87faafcfd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1Jp3D5gdxGrwa5dHbr4p-pECrD8wi7vik\n",
            "From (redirected): https://drive.google.com/uc?id=1Jp3D5gdxGrwa5dHbr4p-pECrD8wi7vik&confirm=t&uuid=08c6352d-ecb3-4cfb-a87c-a20a7ca2d82a\n",
            "To: /content/sentiment_dataset.zip\n",
            "100%|██████████| 182M/182M [00:02<00:00, 61.6MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files extracted successfully to: ./dataset\n"
          ]
        }
      ],
      "source": [
        "import gdown\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "file_url = 'https://drive.google.com/uc?id=1Jp3D5gdxGrwa5dHbr4p-pECrD8wi7vik'\n",
        "file_name = 'sentiment_dataset.zip'\n",
        "\n",
        "# Download the file from Google Drive\n",
        "gdown.download(file_url, file_name, quiet=False)\n",
        "extract_dir = './dataset'\n",
        "\n",
        "# Extract the zip file\n",
        "with zipfile.ZipFile(file_name, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "# Remove the zip file after extraction\n",
        "os.remove(file_name)\n",
        "print(\"Files extracted successfully to:\", extract_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SM10KLjMidnu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z_CiiyyauW5U"
      },
      "source": [
        ">__Note:__</br>\n",
        "**BERT** (Bidirectional Encoder Representations from Transformers) can indeed be trained on a relatively small dataset to yield improved results for certain tasks, especially when fine-tuning a pre-trained model, due to its powerful architecture. It is already pre-trained on larger datasets, possesses powerful contextual understanding, and benefits from effective regularization techniques such as dropout and attention mechanisms, which help prevent overfitting.\n",
        "\n",
        ">So, we can just take just `10000` datasets and train the **BERT** Model on it for our purpose."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "twsVt1DPihlH",
        "outputId": "31194f60-d0fc-415d-c467-927c815af758"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(                                              review sentiment\n",
              " 0  This \\\"hidden gem\\\" bakery and chocolate is th...  positive\n",
              " 1  Great little neighborhood Jewish deli, the Jer...  positive\n",
              " 2  This place was way worse than what I expected....  negative\n",
              " 3  Although I have never stayed here as a guest, ...  positive\n",
              " 4  So, I've enjoyed Mi Cocina before.... but I th...  negative,\n",
              " (10000, 2))"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "# Read dataset and take random 10000 samples\n",
        "df = pd.read_csv(\"dataset/sentiment_combined.csv\")\n",
        "df = df.sample(n=10000, random_state=random.randint(0, 100))\n",
        "\n",
        "# Reset the index\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "df.head(), df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "xHyN1x6Pih5u",
        "outputId": "f20f79d2-2e7a-4ed8-a612-65c2b101fcea"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This \\\\\"hidden gem\\\\\" bakery and chocolate is the best I found so far in the valley!  Chef Gerald makes wonderful chocolate creations (he won the first prize at Glendale Chocolate Festival this year!) out of real Swiss chocolate. Chocolates all hadnmade and they taste heavenly! He also offers a wide variety of European/French pastries which and made fresh daily and taste just like I used to have back home in Europe and even better! My favorite so far is Opera and chocolate with toasted cinnamon apple filling. Absolutely delicious! Check out the website at www.azpastries.com, there is much, much more that chef has to offer!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df['review'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SsFTo9aWi62B",
        "outputId": "095b4a7d-c755-4078-df68-289397a924bf"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentiment\n",
              "negative    5090\n",
              "positive    4910\n",
              "Name: count, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "df['sentiment'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bnkgCW7L1w_h"
      },
      "source": [
        "## 2. Text Pre-Processing\n",
        "\n",
        "- Cleaning up the text data by removing punctuation, extra spaces, and numbers.\n",
        "- Transform sentences into individual words, remove common words (known as \"stop words\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RQ6ShoeAlpPv",
        "outputId": "6c076df9-a137-4d81-8f78-13c8c7978438"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "from collections import Counter\n",
        "\n",
        "# Precompile regular expressions for faster pre processing\n",
        "non_word_chars_pattern = re.compile(r\"[^\\w\\s]\")\n",
        "whitespace_pattern = re.compile(r\"\\s+\")\n",
        "digits_pattern = re.compile(r\"\\d\")\n",
        "username_pattern = re.compile(r\"@([^\\s]+)\")\n",
        "hashtags_pattern = re.compile(r\"#\\d+\")\n",
        "br_pattern = re.compile(r'<br\\s*/?>\\s*<br\\s*/?>')\n",
        "\n",
        "def preprocess_string(s):\n",
        "    # Remove all non-word characters (everything except numbers and letters)\n",
        "    s = non_word_chars_pattern.sub('', s)\n",
        "    # Replace all runs of whitespaces with single space\n",
        "    s = whitespace_pattern.sub(' ', s)\n",
        "    # Replace digits with no space\n",
        "    s = digits_pattern.sub('', s)\n",
        "    # Replace usernames with no space\n",
        "    s = username_pattern.sub('', s)\n",
        "    # Replace hashtags with no space\n",
        "    s = hashtags_pattern.sub('', s)\n",
        "    # Replace <br /> pattern with empty string\n",
        "    s = br_pattern.sub('', s)\n",
        "    # Replace specific characters\n",
        "    s = s.replace(\"https\", \"\")\n",
        "    s = s.replace(\"http\", \"\")\n",
        "    s = s.replace(\"rt\", \"\")\n",
        "    s = s.replace(\"-\", \"\")\n",
        "    # Replace br with empty string\n",
        "    s = s.replace(\"br\", \"\")\n",
        "    # Replace newline character with empty string\n",
        "    s = s.replace(\"\\n\", \"\")\n",
        "    return s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "168852b171034e8aafca596609aa1403",
            "fa4c270216b44a028c06c6e036b947b0",
            "467f1135f29c4a1daab93a60f1989dfa",
            "c279bed378094a1886b7fae62652d4fd",
            "42e767fd87784256bc206ddc41b0b96a",
            "9aa6725a00294cf4a35d6c972da202f4",
            "c9d6e6d8aac4461498a8cd590a62f41f",
            "5af9ca0cdc284afa8362725659f9d92e",
            "e6965818679447b68f61d68852c27f4c",
            "411812c44a494ae895bc818a1eee1333",
            "ea98ae2d3cc14cebb93b7f3b2a78f655"
          ]
        },
        "id": "DyEsn8Lml9PH",
        "outputId": "12e98349-18ce-48b6-c198-fc3679a97c8b"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Preprocessing:   0%|          | 0/10000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "168852b171034e8aafca596609aa1403"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm_notebook\n",
        "\n",
        "preprocessed_reviews = []\n",
        "\n",
        "# Apply preprocessing\n",
        "for review in tqdm_notebook(df['review'], desc='Preprocessing'):\n",
        "    preprocessed_review = preprocess_string(review)\n",
        "    preprocessed_reviews.append(preprocessed_review)\n",
        "\n",
        "# Assign the preprocessed reviews back to  'review' column\n",
        "df['review'] = preprocessed_reviews"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lwgaucZnAkh",
        "outputId": "8b83e6d1-d533-4d02-d0fe-8b156f9b5cb7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('This hidden gem bakery and chocolate is the best I found so far in the valley Chef Gerald makes wonderful chocolate creations he won the first prize at Glendale Chocolate Festival this year out of real Swiss chocolate Chocolates all hadnmade and they taste heavenly He also offers a wide variety of EuropeanFrench pastries which and made fresh daily and taste just like I used to have back home in Europe and even better My favorite so far is Opera and chocolate with toasted cinnamon apple filling Absolutely delicious Check out the website at wwwazpastriescom there is much much more that chef has to offer',\n",
              " 'positive')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "df['review'][0], df['sentiment'][0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BR6tc-oT2Hc1"
      },
      "source": [
        "## 3. Mapping `sentiment` column to numeric values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "vNoB1qL86oPG",
        "outputId": "7770c066-f531-41b1-c60c-1ea2029eab49"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  This hidden gem bakery and chocolate is the be...          1\n",
              "1  Great little neighborhood Jewish deli the Jeru...          1\n",
              "2  This place was way worse than what I expected ...          0\n",
              "3  Although I have never stayed here as a guest w...          1\n",
              "4  So Ive enjoyed Mi Cocina before but I think my...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2bbd326f-d321-49a5-abe3-f11de36970a8\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>This hidden gem bakery and chocolate is the be...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Great little neighborhood Jewish deli the Jeru...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>This place was way worse than what I expected ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Although I have never stayed here as a guest w...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>So Ive enjoyed Mi Cocina before but I think my...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2bbd326f-d321-49a5-abe3-f11de36970a8')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-2bbd326f-d321-49a5-abe3-f11de36970a8 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-2bbd326f-d321-49a5-abe3-f11de36970a8');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-6cdb5946-3655-4b80-a27a-acd98c2b77ac\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-6cdb5946-3655-4b80-a27a-acd98c2b77ac')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-6cdb5946-3655-4b80-a27a-acd98c2b77ac button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 10000,\n  \"fields\": [\n    {\n      \"column\": \"review\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 9999,\n        \"samples\": [\n          \"Hiked during sunset and it was hands down one of the best views of Arizona Ive seen yet Parking is limited and there are multiple trails to walk The most difficult or steepest one leads to this amazing view If you plan to hike at sunset make sure you ing a flashlight Or else its kind of creepy on the way down friend and I basically reenacted a scene from paranormal activitywe survived but just barely \",\n          \"Its cheap Ill say that but otherwise its bland food served by workers who mostly dont seem to notice theyre working and when they do only respond snarkily There are many better vegetarian and vegan options to choose from\",\n          \"Hick Trek is clearly a film that is envious of even an El Mariachilevel budget  Still the creators are able to pull off decent effects at times often due to great editing such as the beamings the situations aboard the cat ship and Slim T Jerks unique way of communicating with his ship without use of a traditional communication device  The acting does have its rough spots but the porayal of Horns McBoy is excellent and Fluffy is ceainly not too hard on the eyes  I do wish that the film had been longer than its approximate hour and that should be seen as a compliment This movie is a success due to the sincerity and hard work of those involved\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# Map 'positive' to 1 & 'negative' to 0\n",
        "df['sentiment'] = df['sentiment'].replace({'positive': 1, 'negative': 0})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9XS665rf2t-9"
      },
      "source": [
        "## 4. Spliiting datasets into train and test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xE28r9W8jFXc",
        "outputId": "50618b9b-7058-48bb-d271-28c326bd6740"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(8000, 2000)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(df['review'],\n",
        "                                                    df['sentiment'],\n",
        "                                                    test_size=0.2)\n",
        "\n",
        "len(X_train), len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "arUMIRZDqr5T",
        "outputId": "a7459f0f-0578-4fb9-a2c0-ca23b54417a3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['This place is just meh They are really trying too hard in some trivial respects and then not hard enough when it comes to the impoant things like the food The ambiance is nice perhaps a bit overdone The service is affable enough But alas the food if they worried a little less about the decor and instead emphasised their focus more on the authenticity of their food then Id be much more satisfied I really could care less about ambiance I dont go to a restaurant for the atmosphere I dont go to a restaurant for the service or to complain to the waitstaff Thats just not how I roll I go for the food The delicious and life sustaining food Notwithstanding the African and black and white zeaprint theme that this place has going on the food as I mentioned is anything but authentic Its just uninspired Maybe its just me but I must have I want I need to taste the heat and the spices of Ethiopia when I eat Ethiopian cuisine This place is not that I think that this resto purposefully caters to patrons who require a more bland and tasteless flavour profile So if you want a watered down version of pseudoEthiopian food then this is probably your jam However if you want delicious and heay and oh so fulfilling Ethiopian cuisine please do hightail it on over to East Africa Restaurant on Sherooke Street West in the hea of NDG and everything delicious will be yours to enjoy Good luck',\n",
              "  'I cant even begin to describe the horrific experience I just had trying to enroll my  year old in their summer camp I spent  minutes registering filling out paperwork trying to get my questions answered and being thrown around and around and around I waited in line  times was never acknowledged until I begged someone at the desk to help me couldnt get any of my questions about swim lessons during camp answered uhjust pick one but you have one during camp so which one is it umits whatever one you want it to be NO IT ISNT dont pretend to know the answer if you are going to make up some bs nnPaperwork says you pay a  deposit for each week which is already pretty steep What the paperwork doesnt say is that you pay a  registration fee a  shi fee  for each week AND  weeks upfront umwhat so Im ready to pay my deposits and everything and the girls says okay your total is  what My kid is a foster kid Im a single mom are you kidding me  for the sign up fee WTF nnI asked the girl to show me where it says that on the paperwork she said oh it doesnt the camp director just decided thats what you will pay she just decided how the eff do people afford that I said seriously she goes I know right sonnso what you people are dumb What kind of ignoramus do you have working the front desk I asked when school staed so I knew how long I wanted to keep her in camp the girl said Im not in school so I dont know you are running summer camp registration you better know when school stas Well since you couldnt answer a single one of my questions why should I expect you to know that nnI finally fork over the money to get away from her and ask where to go she says the gym are you kidding me its the ymca the entire place is a gym I walk down  mile of hallway with  rooms and I see no kids anywhere nnI have to go back to the front again wait in line AGAIN the guy hustles me up and said go back to the gym I said look we have never been here we dont know where we are going can you please just help us He said end of the hall nnThanks jerk nYMCA Im calling you now to cancel this bs membership I hate you and you have ruined my opinions of YMCA everywhere'],\n",
              " [0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "X_train, X_test, y_train, y_test = list(X_train), list(X_test), list(y_train), list(y_test)\n",
        "X_train[:2], y_train[:2]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyrxW-2T20rI"
      },
      "source": [
        "## 5. Preparing data using custom dataloader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sS4L0KVorOIx",
        "outputId": "d74cba4b-b0dd-4bf8-e944-30cdebcb4a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# Setting device agnostic code\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dN_U6_-OtG9V"
      },
      "outputs": [],
      "source": [
        "class data(Dataset):\n",
        "  def __init__(self, encodings, labels):\n",
        "    self.encodings = encodings\n",
        "    self.labels = labels\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    item = {key: torch.tensor(val[index]) for key, val in self.encodings.items()}\n",
        "    item['labels'] = torch.tensor(self.labels[index])\n",
        "    return item\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jIqMd4Kx7h9D"
      },
      "source": [
        "## 6. Load PreTrained BERT Model\n",
        "\n",
        "**BERT** (Bidirectional Encoder Representations from Transformers) is a pre-trained language representation model developed by researchers at Google.\n",
        "\n",
        "<img src = \"https://i0.wp.com/neptune.ai/wp-content/uploads/2022/10/Attention_diagram_transformer.png?ssl=1\">\n",
        "\n",
        "- BERT architecture consists of `multiple encoder transformer blocks` stacked together.\n",
        "- Each transformer block includes` multi-head self-attention` and `feed-forward neural networks`.\n",
        "- `Multi-head self-attention` allows BERT to weigh word importance based on context, capturing long-range dependencies effectively.\n",
        "- The output from `attention mechanisms` undergoes non-linear transformations via `feed-forward neural networks`.\n",
        "- `Layer normalization` and `residual connections` stabilize training and facilitate gradient flow within each transformer block.\n",
        "- `Positional encodings` preserve word order in sequences, aiding BERT in understanding the sequential nature of data.\n",
        "\n",
        ">BERT is pre-trained on a large text corpus using tasks like masked language modeling and next sentence prediction. Fine-tuning on specific tasks involves adjusting the final layers of the pre-trained BERT model.\n",
        "\n",
        "### [Explanation Video on BERT](https://www.youtube.com/watch?v=6ahxPTLZxU8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "M3pUE51Ttyvp",
        "outputId": "3ff4f29d-e10e-4946-fa34-ebb2260e0bc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model_name = 'distilbert-base-uncased'\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFFYOaeg--PW"
      },
      "source": [
        "## 7. Tokenize and Create Encoded Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "6d1E4UWit4PW"
      },
      "outputs": [],
      "source": [
        "# Tokenize with truncation and padding and create dataset from tokenized data\n",
        "train_encoding = tokenizer(X_train, truncation=True, padding=True)\n",
        "test_encoding = tokenizer(X_test, truncation=True, padding=True)\n",
        "\n",
        "train_dataset = data(train_encoding, y_train)\n",
        "test_dataset = data(test_encoding, y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zu7-BCBH-wis"
      },
      "source": [
        "## 8. Fine-Tuning BERT\n",
        "\n",
        "Fine-tuning BERT, a pre-trained language model, allows us to adapt it to specific NLP tasks such as text classification, named entity recognition, sentiment analysis, and question answering.\n",
        "\n",
        "\n",
        "<img src = \"assets/BERT-Fine-tuning-pipeline.png\">"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "x4qy_mL05NVG"
      },
      "outputs": [],
      "source": [
        "training_args = TrainingArguments(\n",
        "  output_dir='./results',            # Directory where model checkpoints & results will be saved\n",
        "  num_train_epochs=3,                # No of training epochs\n",
        "  per_device_train_batch_size=16,    # Batch size for training per device\n",
        "  per_device_eval_batch_size=16,     # Batch size for evaluation per device\n",
        "  learning_rate=1e-05,               # Learning rate for optimizer\n",
        "  warmup_steps=500,                  # No of warmup steps for the learning rate scheduler\n",
        "  weight_decay=0.01,                 # Weight decay coefficient for regularization\n",
        "  logging_dir='./logs',              # Directory for logging training information\n",
        "  load_best_model_at_end=True,       # Whether to load the best model from checkpoints at the end of training\n",
        "  logging_steps=400,                 # Log training metrics every `logging_steps` steps\n",
        "  save_steps=400,                    # Save model checkpoints every `save_steps` steps\n",
        "  evaluation_strategy=\"steps\",       # Evaluate on the evaluation dataset every `logging_steps` steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlH5U0ImAMFJ"
      },
      "source": [
        "## 9. Train the Fine-Tuned BERT Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QaN-z2lExThi",
        "outputId": "b1cec351-371e-44ec-93dc-777087239746"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \n",
            "dataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
        "trainer = Trainer(model=model,\n",
        "                  args=training_args,\n",
        "                  train_dataset=train_dataset,\n",
        "                  eval_dataset=test_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "H1KmmxIQyXK_",
        "outputId": "4ce84eab-3c3f-4bde-8f88-1108e64d1dc0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1500' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1500/1500 20:29, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>400</td>\n",
              "      <td>0.477400</td>\n",
              "      <td>0.241735</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>800</td>\n",
              "      <td>0.226200</td>\n",
              "      <td>0.226347</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1200</td>\n",
              "      <td>0.162500</td>\n",
              "      <td>0.212638</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1500, training_loss=0.2554615732828776, metrics={'train_runtime': 1230.4102, 'train_samples_per_second': 19.506, 'train_steps_per_second': 1.219, 'total_flos': 3179217567744000.0, 'train_loss': 0.2554615732828776, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "from accelerate import Accelerator\n",
        "\n",
        "# Initialize Accelerator and Trainer\n",
        "Accelerator()\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2wlH9_LX9fG2"
      },
      "source": [
        "## 10. Sentiment Prediction using custom text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "EBo9Vmnh8ET8"
      },
      "outputs": [],
      "source": [
        "# Tokenize text, get ouput model and predict\n",
        "def predict_sentiment(model, tokenizer, text, device):\n",
        "    tokenized = tokenizer(text, truncation=True, padding=True, return_tensors='pt').to(device)\n",
        "    outputs = model(**tokenized)\n",
        "    probs = F.softmax(outputs.logits, dim=-1)\n",
        "    preds = torch.argmax(outputs.logits, dim=-1).item()\n",
        "    probs_max = probs.max().detach().cpu().numpy()\n",
        "    prediction = \"Positive\" if preds == 1 else \"Negative\"\n",
        "    print(f'{text}\\nSentiment: {prediction}\\tProbability: {probs_max*100:.2f}%\\n', end=\"-\"*50 + \"\\n\")\n",
        "    # return prediction, probs_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EujVy_419ip4",
        "outputId": "6167410d-b967-4bd4-b60f-e914e6e8dfe0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The traffic was horrendous this morning; I was stuck in it for over an hour.\n",
            "Sentiment: Negative\tProbability: 98.56%\n",
            "--------------------------------------------------\n",
            "I was extremely disappointed with the quality of the product; it didn't meet my expectations at all.\n",
            "Sentiment: Negative\tProbability: 98.98%\n",
            "--------------------------------------------------\n",
            "The customer service at the restaurant was very good; the staff went above and beyond to make us feel welcome.\n",
            "Sentiment: Positive\tProbability: 97.75%\n",
            "--------------------------------------------------\n",
            "My recent stay at Paradise Resort was absolutely fantastic! From the moment I arrived, I was greeted with warm smiles and excellent service. The room was spacious, beautifully decorated, and spotlessly clean. I loved the breathtaking view from my balcony overlooking the pool and tropical gardens. The dining options were exceptional, and the resort's facilities were top-notch, offering everything from a fitness center to guided nature walks. Overall, Paradise Resort exceeded all my expectations, and I can't wait to return for another memorable stay!\n",
            "Sentiment: Positive\tProbability: 99.22%\n",
            "--------------------------------------------------\n",
            "The movie started off promising, but it quickly went downhill. The plot was confusing, the acting was mediocre, and the ending was unsatisfying.\n",
            "Sentiment: Negative\tProbability: 98.90%\n",
            "--------------------------------------------------\n",
            "I had a terrible experience at the restaurant last night. The food was cold, the service was slow, and the staff was rude.\n",
            "Sentiment: Negative\tProbability: 99.05%\n",
            "--------------------------------------------------\n",
            "Despite the initial skepticism, I was pleasantly surprised by the performance of the new smartphone. Its sleek design, impressive camera quality, and fast processing speed exceeded my expectations.\n",
            "Sentiment: Positive\tProbability: 95.87%\n",
            "--------------------------------------------------\n",
            "The concert was absolutely amazing! The energy of the performers, the enthusiasm of the crowd, and the quality of the music made it an unforgettable experience.\n",
            "Sentiment: Positive\tProbability: 98.40%\n",
            "--------------------------------------------------\n",
            "I had high hopes for the book, but it turned out to be a disappointment. The characters were one-dimensional, the plot was predictable, and the writing style was uninspired.\n",
            "Sentiment: Negative\tProbability: 98.35%\n",
            "--------------------------------------------------\n",
            "The presentation was well-prepared and delivered with confidence. The speaker engaged the audience effectively and provided valuable insights on the topic.\n",
            "Sentiment: Positive\tProbability: 98.91%\n",
            "--------------------------------------------------\n",
            "The service at the hotel was impeccable. The staff was attentive, courteous, and always willing to assist with any request.\n",
            "Sentiment: Positive\tProbability: 97.92%\n",
            "--------------------------------------------------\n",
            "The weather during our vacation was dreadful; it rained every day, and we were stuck indoors for most of the trip.\n",
            "Sentiment: Negative\tProbability: 97.92%\n",
            "--------------------------------------------------\n",
            "The hiking trail offered breathtaking views of the mountains and lush forests. It was a challenging but rewarding experience.\n",
            "Sentiment: Positive\tProbability: 98.60%\n",
            "--------------------------------------------------\n",
            "The customer support team was unhelpful and incompetent. They were unable to resolve my issue and seemed indifferent to my concerns.\n",
            "Sentiment: Negative\tProbability: 99.42%\n",
            "--------------------------------------------------\n",
            "The play was a delightful blend of humor, drama, and suspense. The talented cast delivered stellar performances, and the storyline kept me engaged from start to finish.\n",
            "Sentiment: Positive\tProbability: 99.16%\n",
            "--------------------------------------------------\n",
            "The new restaurant in town has quickly become my favorite dining spot. The food is delicious, the atmosphere is cozy, and the service is outstanding.\n",
            "Sentiment: Positive\tProbability: 99.18%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "texts = [\n",
        "    \"The traffic was horrendous this morning; I was stuck in it for over an hour.\",\n",
        "    \"I was extremely disappointed with the quality of the product; it didn't meet my expectations at all.\",\n",
        "    \"The customer service at the restaurant was very good; the staff went above and beyond to make us feel welcome.\",\n",
        "    \"My recent stay at Paradise Resort was absolutely fantastic! From the moment I arrived, I was greeted with warm smiles and excellent service. The room was spacious, beautifully decorated, and spotlessly clean. I loved the breathtaking view from my balcony overlooking the pool and tropical gardens. The dining options were exceptional, and the resort's facilities were top-notch, offering everything from a fitness center to guided nature walks. Overall, Paradise Resort exceeded all my expectations, and I can't wait to return for another memorable stay!\",\n",
        "    \"The movie started off promising, but it quickly went downhill. The plot was confusing, the acting was mediocre, and the ending was unsatisfying.\",\n",
        "    \"I had a terrible experience at the restaurant last night. The food was cold, the service was slow, and the staff was rude.\",\n",
        "    \"Despite the initial skepticism, I was pleasantly surprised by the performance of the new smartphone. Its sleek design, impressive camera quality, and fast processing speed exceeded my expectations.\",\n",
        "    \"The concert was absolutely amazing! The energy of the performers, the enthusiasm of the crowd, and the quality of the music made it an unforgettable experience.\",\n",
        "    \"I had high hopes for the book, but it turned out to be a disappointment. The characters were one-dimensional, the plot was predictable, and the writing style was uninspired.\",\n",
        "    \"The presentation was well-prepared and delivered with confidence. The speaker engaged the audience effectively and provided valuable insights on the topic.\",\n",
        "    \"The service at the hotel was impeccable. The staff was attentive, courteous, and always willing to assist with any request.\",\n",
        "    \"The weather during our vacation was dreadful; it rained every day, and we were stuck indoors for most of the trip.\",\n",
        "    \"The hiking trail offered breathtaking views of the mountains and lush forests. It was a challenging but rewarding experience.\",\n",
        "    \"The customer support team was unhelpful and incompetent. They were unable to resolve my issue and seemed indifferent to my concerns.\",\n",
        "    \"The play was a delightful blend of humor, drama, and suspense. The talented cast delivered stellar performances, and the storyline kept me engaged from start to finish.\",\n",
        "    \"The new restaurant in town has quickly become my favorite dining spot. The food is delicious, the atmosphere is cozy, and the service is outstanding.\",\n",
        "]\n",
        "\n",
        "for text in texts:\n",
        "  predict_sentiment(model, tokenizer, text, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBC6C8VA_Kh4",
        "outputId": "ce79142c-37d4-4da1-9f84-2f8adfbe9645"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Despite facing numerous challenges and setbacks, the team worked tirelessly and managed to exceed all expectations, achieving remarkable success. However, despite their best efforts, the project encountered multiple setbacks, ultimately leading to its failure and significant financial losses.\n",
            "Sentiment: Negative\tProbability: 80.09%\n",
            "--------------------------------------------------\n",
            "The hotel room was clean and comfortable, and the amenities were well-maintained. However, the noise from the nearby construction site was disruptive due to which i could not focus when working. It was annoying as hell.\n",
            "Sentiment: Negative\tProbability: 96.70%\n",
            "--------------------------------------------------\n",
            "The movie had an intriguing plot and captivating visuals, but the sound quality was poor, making it difficult to fully enjoy the experience.\n",
            "Sentiment: Negative\tProbability: 94.92%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# An example of complex review that contains both positive and negative sentiment\n",
        "texts = [\"Despite facing numerous challenges and setbacks, the team worked tirelessly and managed to exceed all expectations, achieving remarkable success. However, despite their best efforts, the project encountered multiple setbacks, ultimately leading to its failure and significant financial losses.\",\n",
        "         \"The hotel room was clean and comfortable, and the amenities were well-maintained. However, the noise from the nearby construction site was disruptive due to which i could not focus when working. It was annoying as hell.\",\n",
        "         \"The movie had an intriguing plot and captivating visuals, but the sound quality was poor, making it difficult to fully enjoy the experience.\"]\n",
        "for text in texts:\n",
        "  predict_sentiment(model, tokenizer, text, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ucfdIBfD62Tr",
        "outputId": "446f6d8b-716b-4ef3-db70-e61c42fb8e73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Despite facing numerous challenges and setbacks, the team worked tirelessly and managed to exceed all expectations, achieving remarkable success.\n",
            "Sentiment: Positive\tProbability: 98.49%\n",
            "--------------------------------------------------\n",
            "However, despite their best efforts, the project encountered multiple setbacks, ultimately leading to its failure and significant financial losses.\n",
            "Sentiment: Negative\tProbability: 90.90%\n",
            "--------------------------------------------------\n",
            "The hotel room was clean and comfortable, and the amenities were well-maintained.\n",
            "Sentiment: Positive\tProbability: 98.35%\n",
            "--------------------------------------------------\n",
            "However, the noise from the nearby construction site was disruptive due to which i could not focus when working.\n",
            "Sentiment: Negative\tProbability: 98.54%\n",
            "--------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Breaking down above example into parts\n",
        "texts = [\"Despite facing numerous challenges and setbacks, the team worked tirelessly and managed to exceed all expectations, achieving remarkable success.\",\n",
        "         \"However, despite their best efforts, the project encountered multiple setbacks, ultimately leading to its failure and significant financial losses.\",\n",
        "         \"The hotel room was clean and comfortable, and the amenities were well-maintained.\",\n",
        "         \"However, the noise from the nearby construction site was disruptive due to which i could not focus when working.\"]\n",
        "\n",
        "for text in texts:\n",
        "  predict_sentiment(model, tokenizer, text, device)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looks like **BERT** can accurately interpret the overall sentiment of the text, recognizing the positive aspects (clean and comfortable room, well-maintained amenities) as well as the negative aspect (disruptive noise from construction). By considering the context and weighing the various sentiments present, BERT can provide a nuanced understanding of the text's sentiment.\n",
        "\n",
        "Overall, BERT's capability to handle mixed sentiments reflects its robustness and versatility in natural language understanding, making it a valuable tool for sentiment analysis and various other NLP tasks."
      ],
      "metadata": {
        "id": "zH1RF9aR5okZ"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "168852b171034e8aafca596609aa1403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa4c270216b44a028c06c6e036b947b0",
              "IPY_MODEL_467f1135f29c4a1daab93a60f1989dfa",
              "IPY_MODEL_c279bed378094a1886b7fae62652d4fd"
            ],
            "layout": "IPY_MODEL_42e767fd87784256bc206ddc41b0b96a"
          }
        },
        "fa4c270216b44a028c06c6e036b947b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9aa6725a00294cf4a35d6c972da202f4",
            "placeholder": "​",
            "style": "IPY_MODEL_c9d6e6d8aac4461498a8cd590a62f41f",
            "value": "Preprocessing: 100%"
          }
        },
        "467f1135f29c4a1daab93a60f1989dfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5af9ca0cdc284afa8362725659f9d92e",
            "max": 10000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6965818679447b68f61d68852c27f4c",
            "value": 10000
          }
        },
        "c279bed378094a1886b7fae62652d4fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_411812c44a494ae895bc818a1eee1333",
            "placeholder": "​",
            "style": "IPY_MODEL_ea98ae2d3cc14cebb93b7f3b2a78f655",
            "value": " 10000/10000 [00:04&lt;00:00, 2896.87it/s]"
          }
        },
        "42e767fd87784256bc206ddc41b0b96a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9aa6725a00294cf4a35d6c972da202f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9d6e6d8aac4461498a8cd590a62f41f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5af9ca0cdc284afa8362725659f9d92e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6965818679447b68f61d68852c27f4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "411812c44a494ae895bc818a1eee1333": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ea98ae2d3cc14cebb93b7f3b2a78f655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}